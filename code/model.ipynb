{"cells":[{"cell_type":"code","source":["from pyspark.ml import Pipeline\nfrom pyspark.ml.classification import LogisticRegression, NaiveBayes\nfrom pyspark.ml.feature import HashingTF, Tokenizer, StopWordsRemover\nfrom pyspark import SparkContext\nfrom pyspark.sql import SQLContext\nfrom pyspark.sql.types import StructType, StructField, IntegerType, StringType, DoubleType\nfrom pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\nfrom pyspark.mllib.evaluation import MulticlassMetrics"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1465ecb3-3a19-4460-ac29-dc19cef78edf","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["sqlContext = SQLContext(sc)\nnewDF = [\n    StructField(\"id\", IntegerType(), True),\n    StructField(\"text\", StringType(), True),\n    StructField(\"label\", DoubleType(), True)]\nfinalSchema = StructType(fields=newDF)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d2b34339-f441-42c6-8bdc-7eb5ccb3bd02","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"/databricks/spark/python/pyspark/sql/context.py:117: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n  warnings.warn(\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["/databricks/spark/python/pyspark/sql/context.py:117: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n  warnings.warn(\n"]}}],"execution_count":0},{"cell_type":"code","source":["dataset = sqlContext.read.format('csv').options(header='true',schema=finalSchema,delimiter='|').load('/FileStore/tables/dataset.csv')\n#types = [f.dataType for f in dataset.schema.fields]\n#print(types)\ndataset = dataset.withColumn(\"label\", dataset[\"label\"].cast(DoubleType()))\ndataset = dataset.withColumn(\"id\", dataset[\"id\"].cast(IntegerType()))\ntraining, test = dataset.randomSplit([0.8, 0.2], seed=12345)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1ccea25c-69f3-40a2-ac7d-5a3a7d9dcc3a","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["\ntokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\nremover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\nhashingTF = HashingTF(inputCol=remover.getOutputCol(), outputCol=\"features\")\nlr = LogisticRegression(maxIter=2, regParam=0.001)\nnb = NaiveBayes(smoothing=1.0, modelType=\"multinomial\")\npipeline = Pipeline(stages=[tokenizer, remover, hashingTF, nb])"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"314297ad-9283-422c-b5be-72cd48736e98","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Fit the pipeline to training documents.\nmodel = pipeline.fit(training)\nresult = model.transform(test)\\\n    .select(\"features\", \"label\", \"prediction\")\ncorrect = result.where(result[\"label\"] == result[\"prediction\"])\naccuracy = correct.count()/test.count()\nprint(\"Accuracy of model = \"+str(accuracy))\ntest_error = 1 - accuracy\nprint (\"Test error = \"+str(test_error))\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d32bb0f1-64ac-4547-ba4f-69f59ba5aa9a","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Accuracy of model = 0.5104166666666666\nTest error = 0.48958333333333337\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Accuracy of model = 0.5104166666666666\nTest error = 0.48958333333333337\n"]}}],"execution_count":0},{"cell_type":"code","source":["evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\nmetric = evaluator.evaluate(result)\nprint(\"F1 metric = \"+ str(metric))\n\nevaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\nmetric = evaluator.evaluate(result)\nprint(\"Recall = \"+ str(metric))\n\nevaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\nmetric = evaluator.evaluate(result)\nprint(\"Precision = \"+ str(metric))\nmodel.save(\"nbmodelNew\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"272aff9f-c2ec-4e28-aad6-a60619aaea4b","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"F1 metric = 0.46053494606126183\nRecall = 0.5104166666666667\nPrecision = 0.5964778414606092\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["F1 metric = 0.46053494606126183\nRecall = 0.5104166666666667\nPrecision = 0.5964778414606092\n"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"spark_pipeline_nb_databricks","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":1719984942905886}},"nbformat":4,"nbformat_minor":0}
